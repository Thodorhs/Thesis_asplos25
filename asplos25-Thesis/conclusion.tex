\section{Conclusions}
Big data analytics frameworks on JVMs are widely used in data centers for large dataset analysis. Research has explored extending the managed heap with fast local storage (e.g., NVMe SSDs) and remote memory, but comprehensive performance and reliability comparisons are lacking. In our comparative analysis, we first employed micro-benchmarks to explore the latency and throughput performance of various storage systems, including local NVMe, remote NVMe, and remote memory. We then selectively compared local device systems with NVMe-oF SPDK NVMe and NVMe-oF SPDK Ram-disk using TeraHeap, which extends the managed heap over these devices. We evaluated these options with 13 widely-used applications in two real-world big data frameworks, Spark and Giraph. The workload reports indicate that NVMe-oF and remote options can match the performance of local ones, yielding very similar results. We found out that the NVMe-oF SPDK NVMe struggles to perform well with the Giraph workloads where there are a lot of writes to objects in the second heap (H2) but the spark workloads have very similar results compared to the local device setup. We also concluded that extending the heap over NVMe-oF SPDK Ram-disk can perform almost the same with the local setup. This study provides valuable insights into the performance characteristics of different storage solutions, informing decisions on resource allocation and system design, and contributing to the ongoing discourse on efficient data management in contemporary computing environments.